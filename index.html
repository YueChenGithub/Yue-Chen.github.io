<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Yue Chen</title>

    <meta name="author" content="Yue Chen">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Welcome to the personal homepage of Yue Chen. Discover my projects, CV, and more.">
    <link rel="shortcut icon" href="imgs/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Yue Chen
                </p>
                <p>Hello! My name is Yue Chen (in chinese: 陈越).
                </p>
                <p> I am actively seeking a a machine learning researcher/engineer position to deepen my exploration and contribution to the field of artificial intelligence.
                </p>
                <p>
                  I completed my Master's Degree in <a href="https://www.tum.de/en/studies/degree-programs/detail/robotics-cognition-intelligence-master-of-science-msc">Robotics, Cognition, Intelligence (RCI)</a> at the <a href="https://www.tum.de/en/">Technical University of Munich (TUM)</a> in 2023, engaging in research in the <a href="https://www.niessnerlab.org/"> Visual Computing & AI Lab</a>. Prior to this, I earned my Bachelor's Degree in <a href="https://www.tum.de/en/studies/degree-programs/detail/mechanical-engineering-bachelor-of-science-bsc"> Mechanical Engineering</a> from TUM in 2021.
                </p>
                <p style="text-align:center">
                  <a href="mailto:yue-c@hotmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="imgs/Lebenslauf%20_en.pdf">CV (English)</a> &nbsp;/&nbsp;
                  <a href="imgs/Lebenslauf%20_de.pdf">CV (German)</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/yue-c/">Linkedin</a> &nbsp;/&nbsp;
                  <a href="https://github.com/YueChenGithub/">Github</a> 
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="imgs/YueChen.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="imgs/YueChen.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  I'm interested in computer vision, computer graphics, deep learning, generative AI, and image processing. My recent work has concentrated on neural rendering, such as 3D scene reconstruction, surface material analysis, and relighting for NeRF.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


            <tr onmouseout="inverser_stop()" onmouseover="inverser_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='inverser_image'><video  width=100% height=100% muted autoplay loop>
                  <source src="imgs/Inverse_rendering.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                  </video></div>
                  <img src='imgs/Inverse_rendering.jpg' width="160">
                </div>
                <script type="text/javascript">
                  function inverser_start() {
                    document.getElementById('inverser_image').style.opacity = "1";
                  }
      
                  function inverser_stop() {
                    document.getElementById('inverser_image').style.opacity = "0";
                  }
                  inverser_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://yuechengithub.github.io/neural-inverse-rendering">
                  <span class="papertitle"> Neural Scene Decomposition for Accurate Light and Material Reconstruction via Physically-Based Global Illumination Estimation</span>
                </a>
                <br>
                <strong>Yue Chen</strong>,
                <a href="https://peter-kocsis.github.io/">Peter Kocsis</a>,
                <a href="https://niessnerlab.org/">Matthias Nießner</a>
                <br>
                <em>Master's Thesis</em>, 2023
                <br>
                <a href="">project page</a>
                /
                <a href="https://github.com/YueChenGithub/neural-inverse-rendering/blob/main/docs/MA_Yue_Chen.pdf">thesis</a>
                /
                <a href="https://github.com/YueChenGithub/neural-inverse-rendering">code</a>
                <p></p>
                <p>
                  Using multi-bounce monte-carlo ray tracing to decompose accurate material properties and lighting conditions of a NeRF scene.
                </p>
              </td>
            </tr>
      
      <tr onmouseout="neuralf_stop()" onmouseover="neuralf_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <div class="two" id='neuralf_image'><video  width=100% height=100% muted autoplay loop>
            <source src="imgs/Neural_Factorization.mp4" type="video/mp4">
            Your browser does not support the video tag.
            </video></div>
            <img src='imgs/Neural_Factorization.jpg' width="160">
          </div>
          <script type="text/javascript">
            function neuralf_start() {
              document.getElementById('neuralf_image').style.opacity = "1";
            }

            function neuralf_stop() {
              document.getElementById('neuralf_image').style.opacity = "0";
            }
            neuralf_stop()
          </script>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="imgs/Neural_Factorization.pdf">
            <span class="papertitle">Neural Factorization of Shape, Material, and Lighting under Unknown Illumination</span>
          </a>
          <br>
          <strong>Yue Chen</strong>,
          <a href="https://github.com/MohamedRamzy1">Mohamed Ebbed</a>,
          <a href="https://github.com/burakcuhadar">Burak Cuhadar</a>,
          <a href="https://peter-kocsis.github.io/">Peter Kocsis</a>
          <br>
          <em>Internship 3DSSL</em>, 2022
          <br>
          <a href="imgs/Neural_Factorization.pdf">report</a>
          <p></p>
          <p>
            Performing 3D scene representation with implicit SDF and estimating light visibility with explicit mesh, reducing the visibility computation time from 150+ hours to 5 minutes.
          </p>
        </td>
      </tr>

      <tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <img src='imgs/visual-grounding.png'>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://github.com/YueChenGithub/visual-grounding/tree/master">
            <span class="papertitle">3D Visual Grounding with Graph and Attention</span>
          </a>
          <br>
          <strong>Yue Chen</strong>, 
          <a href="https://github.com/T-Gu">Tao Gu</a>, 
          <a href="https://daveredrum.github.io/">Dave Zhenyu Chen</a>
          <br>
          <em>ADL4CV Project</em>, 2021
          <br>
          <a href="https://github.com/YueChenGithub/visual-grounding/blob/master/docs/ADL4CVReport.pdf">report</a>
          /
          <a href="https://github.com/YueChenGithub/visual-grounding/tree/master">code</a>
          <p></p>
          <p>Incorporating graph neural networks to model the spatial relationships among object proposals, generating surrounding-aware features.</p>
        </td>
      </tr>


            
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:center;font-size:small;">
                  Design and source code from <a style="font-size:small;" href="https://jonbarron.info">Jon Barron's website</a>
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
